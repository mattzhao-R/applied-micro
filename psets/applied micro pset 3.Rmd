---
title: "Applied Micro PSET 3"
author: "Matthew Zhao"
date: "2023-01-16"
output:
  pdf_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r, message=FALSE, warning=FALSE}
library(tidyverse)
library(haven)
library(stargazer)
library(xtable)
library(lmtest)
library(sandwich)
library(broom)
library(whitestrap)
options(scipen=999)
```

## Question 1

```{r}
df1 <- read_stata('data/Y1.dta')
```

### a)

One of the key motivators that the authors cite is that in developing nations, there has been a large push in making primary school universal and specifically getting students enrolled in primary school. However, the literature reveals that while we are able to get students to attend primary school, this has had little impact on actual learning, with students typically many grade levels behind where they should be in terms of core competencies e.g. literacy and numeracy. 

A survey of past studies reveals that additional resources e.g. smaller classroom size or more textbooks, has little effect for the average student but some effect for students who were above average. As a result, the authors in this paper look to seek if supporting weaker students with remedial education, i.e. providing education that is catered towards their actual level of knowledge, and more broadly if resources which target/adjust to a student's actual level of understanding, would produce gains in literacy and numeracy. 

### b)

```{r}
# cleaning and standardizing data
year1df <- df1 %>%
  select(!c(starts_with('mid'),contains('norm'))) %>%
  filter(!(is.na(pre_verb) | is.na(pre_math) | is.na(post_verb) | is.na(post_math)))

y1_mean_pre_verb_ctrl <- mean((year1df %>% filter(bal == 0))$pre_verb)
y1_sd_pre_verb_ctrl <- sd((year1df %>% filter(bal == 0))$pre_verb)
y1_mean_pre_math_ctrl <- mean((year1df %>% filter(bal == 0))$pre_math)
y1_sd_pre_math_ctrl <- sd((year1df %>% filter(bal == 0))$pre_math)
y1_mean_pre_tot_ctrl <- mean((year1df %>% filter(bal == 0))$pre_tot)
y1_sd_pre_tot_ctrl <- sd((year1df %>% filter(bal == 0))$pre_tot)

y1.cleaned <- year1df %>% 
  mutate(pre_verbnorm = (pre_verb - y1_mean_pre_verb_ctrl)/y1_sd_pre_verb_ctrl,
         pre_mathnorm = (pre_math - y1_mean_pre_math_ctrl)/y1_sd_pre_math_ctrl,
         pre_totnorm = (pre_tot - y1_mean_pre_tot_ctrl)/y1_sd_pre_tot_ctrl,
         post_verbnorm = (post_verb - y1_mean_pre_verb_ctrl)/y1_sd_pre_verb_ctrl,
         post_mathnorm = (post_math - y1_mean_pre_math_ctrl)/y1_sd_pre_math_ctrl,
         post_totnorm = (post_tot - y1_mean_pre_tot_ctrl)/y1_sd_pre_tot_ctrl
         )
```

```{r, warning=F}
# regression balance test
bal_test1_mlr <- lm(bal ~ pre_totnorm + male, data = y1.cleaned)
bal_test1_pretotnorm <- lm(bal ~ pre_totnorm, data = y1.cleaned)
bal_test1_male <- lm(bal ~ male, data = y1.cleaned)
models <- list(bal_test1_pretotnorm,bal_test1_male,bal_test1_mlr)
stargazer(models,type='text',digits=3,
          omit.stat=c('rsq','adj.rsq',"ser"),
          title='Table 1 - Balance Test')
```

We find that the coefficients are insignificantly different from 0 with the implication that the groups are likely balanced. Standard errors for this analysis should be clustered since treatment is randomized at the school level, hence the SEs should be clustered at the school level. 

### c)

```{r, warning=F, message=F}
# table II reproduction
t2_means <- y1.cleaned %>% 
  select(c(schoolid,bal,contains('norm'))) %>%
  pivot_longer(cols = c(contains('norm')),names_to = 'score_cat',values_to='score') %>%
  mutate(bal_cat = ifelse(bal == 1,'Treatment','Comparison')) %>%
  group_by(bal_cat,score_cat) %>%
  summarise(means = mean(score),.groups='keep') %>%
  pivot_wider(names_from = bal_cat, values_from = means) %>%
  filter(!str_detect(score_cat,'tot'))

t2_math_pre <- lm(pre_mathnorm ~ bal, data = y1.cleaned)
t2_verb_pre <- lm(pre_verbnorm ~ bal, data = y1.cleaned)
t2_math_post <- lm(post_mathnorm ~ bal, data = y1.cleaned)
t2_verb_post <- lm(post_verbnorm ~ bal, data = y1.cleaned)

t2_math_pre_robust_clustered <- tidy(coeftest(t2_math_pre,
                                    vcov = vcovCL,
                                    type = "HC1",
                                    cluster = ~schoolid))
t2_verb_pre_robust_clustered <- tidy(coeftest(t2_verb_pre,
                                    vcov = vcovCL,
                                    type = "HC1",
                                    cluster = ~schoolid))
t2_math_post_robust_clustered <- tidy(coeftest(t2_math_post,
                                    vcov = vcovCL,
                                    type = "HC1",
                                    cluster = ~schoolid))
t2_verb_post_robust_clustered <- tidy(coeftest(t2_verb_post,
                                    vcov = vcovCL,
                                    type = "HC1",
                                    cluster = ~schoolid))

#rows <- c('t2_math_pre','t2_verb_pre','t2_math_post','t2_verb_post')
t2_regs <- bind_rows(t2_math_post_robust_clustered,t2_verb_post_robust_clustered, t2_math_pre_robust_clustered,t2_verb_pre_robust_clustered) %>% filter(term == 'bal') %>% select(!c(term,statistic,p.value))
tableII <- bind_cols(t2_means,t2_regs) %>% mutate(across(where(is.numeric), round, 4))
tableII
```

I was able to get similar estimates as Table II of the paper. The estimated treatment effect is 0.146 standard deviations for math and 0.103 standard deviations for language. These seem fairly small, and given the size of the robust clustered standard errors, we cannot say that the treatment has a positive and statistically significant effect on student scores. 

### d)

```{r, warning=F,message=F}
t3_math <- lm((post_mathnorm - pre_mathnorm) ~ bal + pre_totnorm, data=y1.cleaned)
t3_verb <- lm((post_verbnorm - pre_verbnorm) ~ bal + pre_totnorm, data=y1.cleaned)
t3_tot <- lm((post_totnorm - pre_totnorm) ~ bal + pre_totnorm, data=y1.cleaned)

t3_math_robust_clustered <- coeftest(t3_math,
                                    vcov = vcovCL,
                                    type = "HC1",
                                    cluster = ~schoolid)
t3_verb_robust_clustered <- coeftest(t3_verb,
                                    vcov = vcovCL,
                                    type = "HC1",
                                    cluster = ~schoolid)
t3_tot_robust_clustered <- coeftest(t3_tot,
                                    vcov = vcovCL,
                                    type = "HC1",
                                    cluster = ~schoolid)
models <- list(t3_math_robust_clustered,
               t3_verb_robust_clustered,
               t3_tot_robust_clustered)
stargazer(models,type='text',digits=3,
          dep.var.labels=c('Math','Language','Total'),
          omit.stat=c('rsq','adj.rsq',"ser"),
          title='Table 3 - Table III replication: Vadodara Y1 pooled')
```

Compared with the previous simple comparison of means, we find that there is a positive and statistically significant effect of treatment across outcome categories, with all being significant at the 10% level and math and total score being significant at the 1% level. Specifically, we see that controlling for normalized total pretest score improves the precision of estimates of the treatment effect. 

### e)

```{r, warning=F}
df2 <- read_stata('data/Y2.dta')

df_bothyr <- left_join(df1 %>% 
                     select(!contains('post')),
                   df2 %>% 
                     select(!contains('pre')),
                   suffix=c("",".y"), by='studentid',) %>%
  select(!c(starts_with('mid'),contains('norm'),ends_with('.y'))) %>%
  filter(!(is.na(pre_verb) | is.na(pre_math) | is.na(post_verb) | is.na(post_math)))

bothyr_mean_pre_verb_ctrl <- mean((df_bothyr %>% filter(bal == 0))$pre_verb)
bothyr_sd_pre_verb_ctrl <- sd((df_bothyr %>% filter(bal == 0))$pre_verb)
bothyr_mean_pre_math_ctrl <- mean((df_bothyr %>% filter(bal == 0))$pre_math)
bothyr_sd_pre_math_ctrl <- sd((df_bothyr %>% filter(bal == 0))$pre_math)
bothyr_mean_pre_tot_ctrl <- mean((df_bothyr %>% filter(bal == 0))$pre_tot)
bothyr_sd_pre_tot_ctrl <- sd((df_bothyr %>% filter(bal == 0))$pre_tot)

bothyr.cleaned <- df_bothyr %>% 
  mutate(pre_verbnorm = (pre_verb - bothyr_mean_pre_verb_ctrl)/bothyr_sd_pre_verb_ctrl,
         pre_mathnorm = (pre_math - bothyr_mean_pre_math_ctrl)/bothyr_sd_pre_math_ctrl,
         pre_totnorm = (pre_tot - bothyr_mean_pre_tot_ctrl)/bothyr_sd_pre_tot_ctrl,
         post_verbnorm = (post_verb - bothyr_mean_pre_verb_ctrl)/bothyr_sd_pre_verb_ctrl,
         post_mathnorm = (post_math - bothyr_mean_pre_math_ctrl)/bothyr_sd_pre_math_ctrl,
         post_totnorm = (post_tot - bothyr_mean_pre_tot_ctrl)/bothyr_sd_pre_tot_ctrl
         )

bothyr_t3_math <- lm((post_mathnorm - pre_mathnorm) ~ bal + pre_totnorm, data=bothyr.cleaned)
bothyr_t3_verb <- lm((post_verbnorm - pre_verbnorm) ~ bal + pre_totnorm, data=bothyr.cleaned)
bothyr_t3_tot <- lm((post_totnorm - pre_totnorm) ~ bal + pre_totnorm, data=bothyr.cleaned)

bothyr_t3_math_robust_clustered <- coeftest(bothyr_t3_math,
                                    vcov = vcovCL,
                                    type = "HC1",
                                    cluster = ~schoolid)
bothyr_t3_verb_robust_clustered <- coeftest(bothyr_t3_verb,
                                    vcov = vcovCL,
                                    type = "HC1",
                                    cluster = ~schoolid)
bothyr_t3_tot_robust_clustered <- coeftest(bothyr_t3_tot,
                                    vcov = vcovCL,
                                    type = "HC1",
                                    cluster = ~schoolid)
models <- list(bothyr_t3_math_robust_clustered,
               bothyr_t3_verb_robust_clustered,
               bothyr_t3_tot_robust_clustered)
stargazer(models,type='text',digits=3,
          dep.var.labels=c('Math','Language','Total'),
          omit.stat=c('rsq','adj.rsq',"ser"),
          title='Table 3 - Table III replication: Vadodara Two-year pooled')
```

We find similar two-year effects as the paper. Our coefficients are larger now at similar significance levels to part d. Our estimated two-year treatment effect is larger than the one-year treatment effect which makes sense given that the study was designed so that students who received treatment in year 1 in grade 3 would continue to do so in year 2 in grade 4. 

### f)

Internal Validity: could be issues with selection e.g. randomized at school level but could be the case that certain areas are more wealthy and this could result in schools being skewed leading to biased effects?

Another more likely one is partial compliance since we see that in Mumbai not all schools assigned for treatment actually got it since there were administrative issues. Given the reason for not getting treatment, it could be the case that these schools are systematically lower quality than the schools that did receive treatment. This could have potentially biased the estimated effect upwards if students in these schools were more likely to get less benefit from the program. 

There are a larger number of threats to external validity. In particular, since the experiment was conducted in large cities in India, there are doubts as to whether this could generalize to local regions where finding balsakhi may be more difficult. This could be due to administrative burden like in Mumbai or because there are fewer educated young women in less populated areas. 

Furthermore, we do not know if this program could be used in other developing nations to support learning, since it relies on the presence of balsakhi or at least some substitute to keep the program going. 

### g)

```{r}
case1 <- read_stata('data/case1.dta')
```

```{r, warning=F}
# regression balance test
bal_case1_mlr <- lm(treated ~ pre_totnorm + male + income + numstud, data = case1)
bal_case1_pretotnorm <- lm(treated ~ pre_totnorm, data = case1)
bal_case1_male <- lm(treated ~ male, data = case1)
bal_case1_inc <- lm(treated ~ income, data = case1)
bal_case1_numstud <- lm(treated ~ numstud, data = case1)

models <- list(bal_case1_numstud,bal_case1_inc,bal_case1_male)
stargazer(models,type='text',digits=3,column.sep.width = "-15pt",
          omit.stat=c('rsq','adj.rsq',"ser"),
          title='Table 4 - Case 1 Balance Test')
```

```{r, warning=F}
models <- list(bal_case1_pretotnorm,bal_case1_mlr)
stargazer(models,type='text',digits=3,column.sep.width = "-15pt",
          omit.stat=c('rsq','adj.rsq',"ser"),
          title='Table 4 (cont) - Case 1 Balance Test')
```

Here, we identify a potential issue with randomization where it appears that the treatment may not have been perfectly randomized over income, resulting in a significant coefficient and F-stat. Normalized total pre-test score also seems to have a similar relationship which could be explained by the design of the program but should be noted. The other variables appear to be balanced. 

### h)

```{r, warning=F}
case1_base <- lm((Finalscore - pre_totnorm) ~ treated, data=case1)
case1_ov <- lm((Finalscore - pre_totnorm) ~ treated + pre_totnorm + income, data=case1)
models <- list(case1_base,case1_ov)
stargazer(models,type='text',digits=3,
          column.sep.width = "-15pt",
          omit.stat=c('rsq','adj.rsq',"ser"),
          title='Table 5 - Case 1 Estimate of Causal Effect')
```

I estimate the causal effect of treatment on score to be around 0.3 standard deviations. I show that controlling for other pre-treatment variables noted in the balance test does not change the effect from the baseline regression. Since the estimate of the causal effect is robust to these variables, I believe that this estimate is the causal effect of interest to the extent that we have shown randomization and can assume the treatment is uncorrelated with unobservables from that. We are also told there is no attrition. 

### i)

```{r, warning=F}
case1_base <- lm((Finalscore - pre_totnorm) ~ treated, data=case1)
case1_ov <- lm((Finalscore - pre_totnorm) ~ treated + pre_totnorm + income, data=case1)
case1_ctrl <- lm((Finalscore - pre_totnorm) ~ treated + pre_totnorm + income + male + std + numstud, data=case1)

# checking for heteroskedasticity
bptest(case1_base)
white_test(case1_base)
```

```{r, warning=F}
models <- list(case1_base,case1_ov,case1_ctrl)
stargazer(models,type='text',digits=3,
          column.sep.width = "-15pt",
          omit.stat=c('rsq','adj.rsq',"ser"),
          title='Table 6 - Case 1 Alternative Specifications')
```

We do not see any heteroskedasticity based on the BP and White tests. Furthermore, we cannot improve the precision of our estimate with additional controls. 

### j)

```{r}
ggplot(data = case1, mapping=aes(x=Finalscore - pre_totnorm)) + 
  geom_histogram(bins=15) + 
  facet_grid(male~cut(income,3))
```

```{r}
ggplot(data = case1, mapping=aes(x=Finalscore - pre_totnorm)) + 
  geom_histogram(bins=15) + 
  facet_grid(std~cut(numstud,3))
```

The treatment effect appears to be similar across gender and grade. Additionally, while we see a slightly more left skewed distribution of treatment effects for smaller classrooms and lower income, the difference is fairly negligible.  

### k)

```{r, warning=F}
# true effect
mean(case1$Y1 - case1$Y0)
```

```{r, fig.dim=c(5,4), out.width='75%'}
ggplot(data = case1, mapping=aes(x=Y1 - Y0)) + 
  geom_histogram(bins=30) +
  ggtitle('Treatment effect for whole sample')
ggplot(data = case1 %>% filter(treated == 1), mapping=aes(x=Y1 - Y0)) + 
  geom_histogram(bins=30) +
  ggtitle('Treatment effect for Treated')
ggplot(data = case1 %>% filter(treated == 0), mapping=aes(x=Y1 - Y0)) + 
  geom_histogram(bins=30) +
  ggtitle('Treatment effect for Untreated')

case1 %>% 
  mutate(trt_effect = cut(Y1-Y0,10)) %>%
  group_by(trt_effect) %>%
  count()
```

We see that the treatment effect is roughly normally distributed across the sample. Furthermore, we see little evidence of sorting or any selection in relation to the treatment. Since our subgroup analysis in part j revealed little difference across observable groups, we do not further investigate these variables. 

### l)

```{r}
case2 <- read_stata('data/case2.dta')
```

```{r, warning=F}
# regression balance test
bal_case2_mlr <- lm(treated ~ pre_totnorm + male + income + numstud + side, data = case2)
bal_case2_pretotnorm <- lm(treated ~ pre_totnorm, data = case2)
bal_case2_side <- lm(treated ~ side, data = case2)
bal_case2_male <- lm(treated ~ male, data = case2)
bal_case2_inc <- lm(treated ~ income, data = case2)
bal_case2_numstud <- lm(treated ~ numstud, data = case2)

models <- list(bal_case2_numstud,bal_case2_inc,bal_case2_male)
stargazer(models,type='text',digits=3,column.sep.width = "-15pt",
          omit.stat=c('rsq','adj.rsq',"ser"),
          title='Table 7 - Case 2 Balance Test')
```

```{r, warning=F}
models <- list(bal_case2_pretotnorm,bal_case2_side,bal_case2_mlr)
stargazer(models,type='text',digits=3,column.sep.width = "-15pt",
          omit.stat=c('rsq','adj.rsq',"ser"),
          title='Table 7 (cont) - Case 2 Balance Test')
```

Since the F-stats are all small and insignificant, we can conclude that the groups are balanced. 

### m)

```{r, warning=F}
case2_base <- lm((Finalscore - pre_totnorm) ~ treated, data=case2)
case2_unobs <- lm((Finalscore - pre_totnorm) ~ treated + pre_totnorm + income, data=case2)
case2_ov <- lm((Finalscore - pre_totnorm) ~ treated + pre_totnorm + income + side, data=case2)

stargazer(list(case2_base,case2_unobs,case2_ov),type='text',digits=4,
          column.sep.width = "-15pt",
          omit.stat=c('rsq','adj.rsq',"ser"),
          title='Table 8 - Case 2 Estimate of Causal Effect')
```

```{r}
# checking for heteroskedasticity
print('Base Case:')
bptest(case2_base)
white_test(case2_base)
print('With Controls:')
bptest(case2_unobs)
white_test(case2_unobs)
print('With Controls + side:')
bptest(case2_ov)
white_test(case2_ov)
```

```{r, warning=F}
case2_base_robust <- coeftest(case2_base, vcov = vcovHC(case2_base, type = 'HC1'))
case2_unobs_robust <- coeftest(case2_unobs, vcov = vcovHC(case2_unobs, type = 'HC1'))

round(case2_base_robust,4)
round(case2_unobs_robust,4)
```

After examining the inital regression results, I testd for heteroskedasticity using the BP and White tests. I find that the tests strongly reject the null of homoskedasticity for both the baseline model and the model with observed controls As a result, I re-estimate the models with robust standard errors, finding negligible change. 

I estimate the causal effect of treatment on score to be around 0.0467 standard deviations. After using robust standard errors, the baseline model should no longer exhibit heteroskedasticity, with the standard errors and estimate of treatment effect not changing. Furthermore, I believe that the estimate of $\beta_D$ is consistent here because side is correlated with the outcome (Finalscore-pre_totnorm) but is uncorrelated with treated. 

### n)

```{r, warning=F}
case2_base <- lm((Finalscore - pre_totnorm) ~ treated, data=case2)
case2_ov <- lm((Finalscore - pre_totnorm) ~ treated + pre_totnorm + income + side, data=case2)
case2_ctrl <- lm((Finalscore - pre_totnorm) ~ treated + pre_totnorm + income + male + std + numstud + side, data=case2)
```

```{r, warning=F}
models <- list(case2_base,case2_ov,case2_ctrl)
stargazer(models,type='text',digits=4,
          column.sep.width = "-15pt",
          omit.stat=c('rsq','adj.rsq',"ser"),
          title='Table 9 - Case 2 Alternative Specifications')
```

We can improve the precision of our estimate of the treatment effect by adding in side since it uniquely accounts for a portion of the variation in our outcome since it is correlated with Y but not D or any other controls. 

### o)

```{r}
ggplot(data = case2, mapping=aes(x=Finalscore - pre_totnorm)) + 
  geom_histogram(bins=15) + 
  facet_grid(male~cut(income,5))
```

```{r}
ggplot(data = case2, mapping=aes(x=Finalscore - pre_totnorm)) + 
  geom_histogram(bins=15) + 
  facet_grid(side~cut(income,3))
```

The treatment effect differs across side, with side == 1 being shifted right (higher difference in SD score) and side == 0 shifted left (lower difference in SD score). 

### p)

```{r, warning=F}
# true effect
mean(case2$Y1 - case2$Y0)
```

```{r, fig.dim=c(5,4), out.width='75%'}
ggplot(data=case2, mapping=aes(x=Y1-Y0)) + 
  geom_density(mapping=aes(fill=as.factor(side)),alpha = 0.2)
ggplot(data=case2, mapping=aes(x=Y1-Y0)) +
  geom_density(alpha = 0.2)
```

```{r}
case2 %>%
  group_by(side) %>%
  summarise(score_diff = mean(Finalscore-pre_totnorm),.groups = 'keep')
```

Our estimate of the treatment effect is slightly higher than the actual treatment effect. This could be due to sorting, where those who will benefit more from the treatment e.g. those with side == 1 tend to be in the treatment group more often. Since side is unobserved, it is difficult to account for when stratifying a sample for randomization and poses selection concerns.

### q)

```{r, fig.dim=c(5,4), out.width='75%'}
ggplot(data=case2, mapping=aes(x=Y1-Y0)) + 
  geom_density(alpha = 0.2) + 
  facet_wrap(~side,nrow=2)
```

The treatment effect is higher for those with side == 1 than side == 0. As a result, our estimated causal effect of treatment in part m is slightly off because while the distribution of side == 1 and side == 0 is roughly even across treated and untreated groups, the effect of treatment on those with side == 1 is more positive than the effect of treatment on those with side == 0 is negative. As a result, there is a slight upwards bias on the estimated effect in m since the two groups which split the sample have a non-insignificant difference in conditional average treatment effect. 

### r)

The average effect for the treated is not meaningful in this case because there are two distinctly separate groups which have different CATT that are not only different magnitude but more importantly in different directions. As a result, we care significantly more about the conditional average treatment effect, especially if side is an indicator for a threshold of total family wealth e.g. if side == 1 represents below poverty line we would want to specifically target those who would actually benefit and avoid treating those who would be negatively affected. 

### s)

```{r}
case3 <- read_stata('data/case3.dta')
```

```{r, warning=F}
# regression balance test
tgbal_case3_mlr <- lm(TreatmentGroup ~ pre_totnorm + male + income + numstud, data = case3)
tgbal_case3_pretotnorm <- lm(TreatmentGroup ~ pre_totnorm, data = case3)
tgbal_case3_male <- lm(TreatmentGroup ~ male, data = case3)
tgbal_case3_inc <- lm(TreatmentGroup ~ income, data = case3)
tgbal_case3_numstud <- lm(TreatmentGroup ~ numstud, data = case3)

models <- list(tgbal_case3_numstud,tgbal_case3_inc,tgbal_case3_male)
stargazer(models,type='text',digits=3,column.sep.width = "-15pt",
          omit.stat=c('rsq','adj.rsq',"ser"),
          title='Table 10 - Case 3 Treatment Group Balance Test')
```

```{r, warning=F}
models <- list(tgbal_case3_pretotnorm,tgbal_case3_mlr)
stargazer(models,type='text',digits=3,column.sep.width = "-15pt",
          omit.stat=c('rsq','adj.rsq',"ser"),
          title='Table 10 (cont) - Case 3 Treatment Group Balance Test')
```

### t)



### u)



### v)



### w)



### x)



### y)



### z)



## Problem 2



### a)



### b)



### c)



### d)





